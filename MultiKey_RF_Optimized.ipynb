{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "88473e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from pyope.ope import OPE, ValueRange\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import os\n",
    "from tqdm.auto import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from umbral import encrypt, decrypt_reencrypted, reencrypt, generate_kfrags\n",
    "from umbral.keys import SecretKey, PublicKey\n",
    "from umbral.signing import Signer\n",
    "from collections import Counter\n",
    "from umbral.capsule_frag import VerifiedCapsuleFrag\n",
    "from joblib import Parallel, delayed\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4690b011",
   "metadata": {},
   "source": [
    "### Key Initialization and Loading\n",
    "\n",
    "This section loads all necessary cryptographic keys from a `keys.json` file:\n",
    "\n",
    "- **OPE Keys**: Loaded for each decision tree, used to encrypt feature thresholds.\n",
    "- **PRE Keys**: Loaded for a fixed number of groups, used to encrypt and re-encrypt class labels.\n",
    "- **Voting Key**: A global key used for decrypting the final prediction after proxy re-encryption.\n",
    "\n",
    "The OPE keys are used per-tree, while PRE keys are grouped across trees to enable multi-key encryption. The voting key is used in the final decryption phase after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fdc2ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keys from JSON file\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    key_data = json.load(f)\n",
    "\n",
    "in_range = ValueRange(0, 2550)\n",
    "out_range = ValueRange(0, 2**32 - 1)\n",
    "\n",
    "num_estimators = 1  # Number of trees in the RF\n",
    "num_keys = 1    # Number of PRE keys/groups\n",
    "\n",
    "if num_keys > num_estimators:\n",
    "    raise ValueError(\"The number of keys cannot exceed the number of estimators.\")\n",
    "\n",
    "# Index used to choose the keys from the JSON file\n",
    "start_idx = 0\n",
    "end_idx_ope = start_idx + num_estimators\n",
    "end_idx_pre = start_idx + num_keys  # Only take num_keys PRE keys\n",
    "\n",
    "# Load OPE keys (each tree still uses a unique OPE key)\n",
    "ope_keys = [OPE(key.encode(), in_range=in_range, out_range=out_range)\n",
    "            for key in key_data[\"ope_keys\"][start_idx:end_idx_ope]]\n",
    "\n",
    "# Load PRE keys (only num_keys for grouped encryption)\n",
    "pre_secret_keys = [\n",
    "    SecretKey.from_bytes(bytes.fromhex(k))\n",
    "    for k in key_data[\"pre_keys\"][\"private_keys\"][start_idx:end_idx_pre]\n",
    "]\n",
    "pre_public_keys = [\n",
    "    PublicKey.from_bytes(bytes.fromhex(k))\n",
    "    for k in key_data[\"pre_keys\"][\"public_keys\"][start_idx:end_idx_pre]\n",
    "]\n",
    "\n",
    "# Load voting key\n",
    "vote_secret_key = SecretKey.from_bytes(bytes.fromhex(key_data[\"vote_key\"][\"private\"]))\n",
    "vote_public_key = PublicKey.from_bytes(bytes.fromhex(key_data[\"vote_key\"][\"public\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e678e3",
   "metadata": {},
   "source": [
    "### Key Management and Tree Grouping\n",
    "\n",
    "This section performs the following tasks:\n",
    "\n",
    "- Groups decision trees evenly across multiple PRE keys.\n",
    "- Generates Proxy Re-Encryption (PRE) key pairs for each group.\n",
    "- Generates kfrags (key fragments) that allow re-encryption from each group key to a common voting key.\n",
    "\n",
    "The grouping ensures that each PRE key encrypts approximately the same number of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e137de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the total number of estimators into groups based on the number of PRE keys\n",
    "def generate_tree_groups(num_estimators, num_keys):\n",
    "    base = num_estimators // num_keys            # Minimum number of trees per group\n",
    "    remainder = num_estimators % num_keys        # Distribute the remaining trees\n",
    "\n",
    "    tree_groups = []\n",
    "    start = 0\n",
    "    for i in range(num_keys):\n",
    "        group_size = base + (1 if i < remainder else 0)  # Distribute remainder across first few groups\n",
    "        group = list(range(start, start + group_size))   # Assign tree indices to this group\n",
    "        tree_groups.append(group)\n",
    "        start += group_size\n",
    "    return tree_groups\n",
    "\n",
    "# Generate tree-to-key groups based on the number of estimators and keys\n",
    "tree_groups = generate_tree_groups(num_estimators, num_keys)\n",
    "\n",
    "\n",
    "# Generate a list of random PRE secret keys and their corresponding public keys\n",
    "def generate_group_keys(num_keys):\n",
    "    group_secret_keys = [SecretKey.random() for _ in range(num_keys)]\n",
    "    group_public_keys = [sk.public_key() for sk in group_secret_keys]\n",
    "    return group_secret_keys, group_public_keys\n",
    "\n",
    "\n",
    "# Generate kfrags (key fragments) for each group to allow re-encryption to the voting key\n",
    "def generate_kfrags_for_groups(group_secret_keys, vote_public_key):\n",
    "    group_kfrags = []\n",
    "    for sk in group_secret_keys:\n",
    "        signer = Signer(sk)  # Signer is needed to verify kfrags\n",
    "        kfrags = generate_kfrags(\n",
    "            delegating_sk=sk,\n",
    "            receiving_pk=vote_public_key,\n",
    "            signer=signer,\n",
    "            threshold=1,\n",
    "            shares=1,\n",
    "            sign_delegating_key=True,\n",
    "            sign_receiving_key=True\n",
    "        )\n",
    "        group_kfrags.append(kfrags)\n",
    "    return group_kfrags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6992d8",
   "metadata": {},
   "source": [
    "### PRE Decryption Function\n",
    "\n",
    "This function handles the decryption of a Proxy Re-Encrypted (PRE) ciphertext. It performs the following steps:\n",
    "\n",
    "- Extracts the original `cfrags` from verified `kfrags`.\n",
    "- Uses the PRE `decrypt_reencrypted` function with the voting secret key and delegation public key.\n",
    "- Measures and returns the decryption time alongside the decrypted result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0bbc4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrypt a re-encrypted ciphertext using PRE and measure the decryption time\n",
    "def decrypt_pre(ciphertext, capsule, kfrags, vote_secret_key, delegating_pk):\n",
    "    start = time.perf_counter()  # Start timing the decryption\n",
    "\n",
    "    # Extract raw capsule fragments from the verified capsule fragments\n",
    "    cfrags = [vcfrag.cfrag for vcfrag in kfrags]\n",
    "\n",
    "    # Perform decryption using the PRE library's re-encryption decryption function\n",
    "    decrypted = decrypt_reencrypted(\n",
    "        receiving_sk=vote_secret_key,   # Final secret key that receives the re-encrypted data\n",
    "        delegating_pk=delegating_pk,    # Public key of the delegator\n",
    "        capsule=capsule,                # Capsule containing encrypted metadata\n",
    "        verified_cfrags=cfrags,         # Verified fragments used to reconstruct access\n",
    "        ciphertext=ciphertext           # Encrypted label\n",
    "    )\n",
    "\n",
    "    end = time.perf_counter()  # End timing\n",
    "    decryption_time = end - start\n",
    "\n",
    "    return decrypted, decryption_time  # Return both result and time taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1290bee",
   "metadata": {},
   "source": [
    "### Grouped Majority Voting with PRE\n",
    "\n",
    "This function performs secure majority voting using grouped encrypted predictions. For each group:\n",
    "- It determines the local majority vote.\n",
    "- Re-encrypts the vote using a kfrag.\n",
    "- Decrypts the re-encrypted vote using the voting secret key.\n",
    "\n",
    "The final result is computed by majority voting over all group-level decrypted predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7f2c84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grouped majority voting using PRE-decrypted labels\n",
    "def grouped_majority_voting_with_pre(grouped_votes, grouped_capsules, group_keys, group_kfrags, vote_secret_key):\n",
    "    final_votes = []\n",
    "\n",
    "    for i in range(len(grouped_votes)):\n",
    "        # Get the most common vote in the current group\n",
    "        group_vote = Counter(grouped_votes[i]).most_common(1)[0][0]\n",
    "\n",
    "        # Retrieve the capsule and kfrag for the group\n",
    "        capsule = grouped_capsules[i][0]\n",
    "        kfrag = group_kfrags[i][0]\n",
    "\n",
    "        # Re-encrypt the capsule using the provided kfrag\n",
    "        cfrag = reencrypt(capsule, kfrag)\n",
    "        verified_cfrag = VerifiedCapsuleFrag(cfrag)\n",
    "\n",
    "        # Decrypt the re-encrypted ciphertext\n",
    "        decrypted, _ = decrypt_pre(\n",
    "            ciphertext=group_vote,\n",
    "            capsule=capsule,\n",
    "            kfrags=[verified_cfrag],\n",
    "            vote_secret_key=vote_secret_key,\n",
    "            delegating_pk=group_keys[i]\n",
    "        )\n",
    "\n",
    "        # Append the decoded decrypted vote\n",
    "        final_votes.append(decrypted.decode())\n",
    "\n",
    "    # Return the overall majority vote from all groups\n",
    "    return Counter(final_votes).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578ca6c",
   "metadata": {},
   "source": [
    "### Dataset Loading and Timing\n",
    "\n",
    "This section loads the MNIST dataset using `fetch_openml` and measures the time required to complete the operation. The dataset will later be used for training and testing the Random Forest classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c41b42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loading Time: 4.6908 seconds\n"
     ]
    }
   ],
   "source": [
    "start_total_time = time.perf_counter()  # Start total execution time\n",
    "\n",
    "# Load Dataset Used for Testing and Training\n",
    "start_dataset_load_time = time.perf_counter()\n",
    "\n",
    "# Fetch MNIST dataset from OpenML and convert to NumPy arrays\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X, y = mnist.data.astype(\"float32\"), mnist.target.astype(\"int\")\n",
    "\n",
    "end_dataset_load_time = time.perf_counter()\n",
    "\n",
    "# Calculate dataset load time\n",
    "dataset_load_time = end_dataset_load_time - start_dataset_load_time\n",
    "print(f\"Dataset Loading Time: {dataset_load_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b8031",
   "metadata": {},
   "source": [
    "### Dataset Scaling\n",
    "\n",
    "This section normalizes the dataset to ensure all pixel values fall within the required encryption range. \n",
    "The raw MNIST images are first scaled to the [0, 1] range, then rescaled to the [0, 2550] integer range to match the input range expected by the OPE encryption scheme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a4bddca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "X = X / 255.0\n",
    "\n",
    "if X.max() <= 1:\n",
    "    # Rescale dataset from original range to [0, 255]\n",
    "    X = (X - X.min()) / (X.max() - X.min()) * 255\n",
    "    X = (X * 10).astype(int)  # Scale to 0â€“2550\n",
    "else:\n",
    "    X = X.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4dea3",
   "metadata": {},
   "source": [
    "### Dataset Splitting\n",
    "\n",
    "The dataset is split into training and testing sets. The total number of samples in each set is recorded. \n",
    "These values are used to control the scope of encryption and evaluation throughout the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ec4a4f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 56000\n",
      "Number of testing samples: 14000\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Get the number of samples to be encrypted\n",
    "num_samples_training = len(X_train)\n",
    "num_samples_testing = len(X_test)\n",
    "\n",
    "print(f\"Number of training samples: {num_samples_training}\")\n",
    "print(f\"Number of testing samples: {num_samples_testing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0129ee",
   "metadata": {},
   "source": [
    "### Grouped Dataset Encryption with OPE\n",
    "\n",
    "This function encrypts the input dataset `X_data` using Order-Preserving Encryption (OPE) on a per-group basis. Each group uses a shared OPE key, and encryption is parallelized across chunks of rows to improve performance.\n",
    "\n",
    "If cached encrypted data exists and matches the expected shape, it is loaded from disk. Otherwise, the data is encrypted in chunks, stored, and reused for all trees in the corresponding group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dca80f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encrypt a single chunk of rows using OPE\n",
    "def encrypt_chunk(chunk, ope):\n",
    "    return [[ope.encrypt(int(val)) for val in row] for row in chunk]\n",
    "\n",
    "# Encrypt dataset grouped by shared OPE keys across decision tree groups\n",
    "def load_or_encrypt_dataset_grouped(X_data, tree_groups, ope_keys, key_data, chunk_size=500):\n",
    "    encrypted_versions = []\n",
    "    encryption_times = []\n",
    "\n",
    "    for group_idx, tree_indices in enumerate(tree_groups):\n",
    "        key_name = key_data[\"ope_keys\"][group_idx]\n",
    "        ope = ope_keys[group_idx]\n",
    "        file_path = f\"Encrypted_Dataset/X_test_encrypted_{key_name}.npy\"\n",
    "\n",
    "        # Use cached encrypted dataset if available and matches input size\n",
    "        if os.path.exists(file_path):\n",
    "            encrypted_X = np.load(file_path)\n",
    "            if encrypted_X.shape[0] != X_data.shape[0]:\n",
    "                print(f\"Mismatch shape in cached file for key: {key_name}. Re-encrypting...\")\n",
    "                os.remove(file_path)\n",
    "            else:\n",
    "                print(f\"[Group {group_idx + 1}] Loaded cached data for key: {key_name[:8]}...\")\n",
    "                encryption_times.append(0)\n",
    "                for _ in tree_indices:\n",
    "                    encrypted_versions.append(encrypted_X)\n",
    "                continue\n",
    "\n",
    "        print(f\"[Group {group_idx + 1}] Encrypting test data with key: {key_name[:8]}...\")\n",
    "\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Split dataset into smaller chunks for parallel encryption\n",
    "        num_samples = X_data.shape[0]\n",
    "        chunks = [X_data[i:i + chunk_size] for i in range(0, num_samples, chunk_size)]\n",
    "\n",
    "        encrypted_chunks = []\n",
    "        for chunk in tqdm(chunks, desc=f\"Encrypting (Group {group_idx + 1})\", unit=\"chunk\"):\n",
    "            encrypted = Parallel(n_jobs=-1)(\n",
    "                delayed(encrypt_chunk)([row], ope) for row in chunk\n",
    "            )\n",
    "            # Flatten nested lists to a single list of rows\n",
    "            encrypted_chunks.extend([item[0] for item in encrypted])\n",
    "\n",
    "        encrypted_X = np.array(encrypted_chunks)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        # Save encrypted data for future reuse\n",
    "        os.makedirs(\"Encrypted_Dataset\", exist_ok=True)\n",
    "        np.save(file_path, encrypted_X)\n",
    "        print(f\"[Group {group_idx + 1}] Saved encrypted data to: {file_path}\")\n",
    "        encryption_times.append(end - start)\n",
    "\n",
    "        # Share the same encrypted dataset with all trees in the current group\n",
    "        for _ in tree_indices:\n",
    "            encrypted_versions.append(encrypted_X)\n",
    "\n",
    "    return encrypted_versions, encryption_times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eec912",
   "metadata": {},
   "source": [
    "### Encrypt Test Dataset Using Grouped OPE\n",
    "\n",
    "This block performs encryption of the test dataset using the grouped OPE approach. It measures the total encryption time and prints the shape of the encrypted dataset. If cached versions are used, the encryption time is reported as zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "99d3e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test size: (14000, 784)\n",
      "[Group 1] Loaded cached data for key: 5f5e8a3f...\n",
      "\n",
      "Total Dataset Encryption Time (Grouped OPE + Chunked): 0.0413 seconds\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the test dataset\n",
    "print(f\"X_test size: {X_test.shape}\")\n",
    "\n",
    "# Start timing the encryption process\n",
    "start_test_data_encryption_time = time.perf_counter()\n",
    "\n",
    "# Encrypt or load encrypted test dataset for each group of trees\n",
    "X_test_encrypted_per_tree, encryption_times = load_or_encrypt_dataset_grouped(\n",
    "    X_test, tree_groups, ope_keys, key_data, chunk_size=50\n",
    ")\n",
    "\n",
    "end_test_data_encryption_time = time.perf_counter()\n",
    "\n",
    "# Determine encryption time: use total duration if loaded from cache, or sum of all group encryption times\n",
    "test_data_encryption_time = (\n",
    "    end_test_data_encryption_time - start_test_data_encryption_time\n",
    "    if all(t == 0 for t in encryption_times)\n",
    "    else sum(encryption_times)\n",
    ")\n",
    "\n",
    "# Print final encryption time\n",
    "print(f\"\\nTotal Dataset Encryption Time (Grouped OPE + Chunked): {test_data_encryption_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbbae6",
   "metadata": {},
   "source": [
    "### Random Forest Training\n",
    "\n",
    "A Random Forest classifier is trained on the plaintext training data to construct the model used for encrypted inference.\n",
    "The number of decision trees and maximum depth are defined in the initialization. \n",
    "\n",
    "The training time is measured to compare against the full encryption and classification pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8790b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Time: 0.4559 seconds\n"
     ]
    }
   ],
   "source": [
    "start_training_time = time.perf_counter()\n",
    "\n",
    "clf_ope = RandomForestClassifier(n_estimators=num_estimators, max_depth=20, random_state=42, min_samples_split=2)\n",
    "clf_ope.fit(X_train, y_train)\n",
    "\n",
    "end_training_time = time.perf_counter()\n",
    "training_time = end_training_time - start_training_time\n",
    "\n",
    "print(f\"Random Forest Training Time: {training_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e301c",
   "metadata": {},
   "source": [
    "### Label Encryption with Proxy Re-Encryption (PRE)\n",
    "\n",
    "This section encrypts the predicted class labels at the leaf nodes of each decision tree using Proxy Re-Encryption (PRE). It consists of two parts:\n",
    "\n",
    "- `encrypt_single_tree`: Encrypts the labels of a single decision tree using a shared group PRE public key.\n",
    "- `encrypt_tree_labels_with_pre`: Runs the label encryption in parallel across all trees in the Random Forest using multithreading.\n",
    "\n",
    "The result includes encrypted labels and capsules for each tree, along with the total encryption time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8b5ca336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encrypt the leaf node labels of a single decision tree using a given PRE key\n",
    "def encrypt_single_tree(tree_idx, feature, value, group_idx, pre_key_bytes, max_labels_per_tree=None):\n",
    "    tree_values = {}\n",
    "    tree_capsules = {}\n",
    "\n",
    "    # Convert the PRE public key from bytes\n",
    "    pre_key = PublicKey.from_bytes(bytes.fromhex(pre_key_bytes))\n",
    "\n",
    "    # Identify leaf nodes in the decision tree\n",
    "    leaf_nodes = [i for i in range(len(feature)) if feature[i] == -2]\n",
    "    if max_labels_per_tree is not None:\n",
    "        leaf_nodes = leaf_nodes[:max_labels_per_tree]  # Limit encryption to a subset if specified\n",
    "\n",
    "    # Encrypt the predicted label at each leaf node\n",
    "    for node in leaf_nodes:\n",
    "        label = str(np.argmax(value[node][0]))\n",
    "        capsule, ciphertext = encrypt(pre_key, label.encode())\n",
    "        tree_values[node] = ciphertext\n",
    "        tree_capsules[node] = capsule\n",
    "\n",
    "    return tree_values, tree_capsules\n",
    "\n",
    "\n",
    "# Encrypt the labels of all trees using PRE, in parallel\n",
    "def encrypt_tree_labels_with_pre(clf, pre_public_keys, tree_groups, max_labels_per_tree=None):\n",
    "    start_label_encryption_time = time.perf_counter()\n",
    "    print(\"Encrypting leaf labels using PRE (Parallel)...\")\n",
    "\n",
    "    jobs = []\n",
    "\n",
    "    # Prepare encryption jobs for each tree based on its group\n",
    "    for idx, tree in enumerate(clf.estimators_):\n",
    "        group_idx = next(i for i, group in enumerate(tree_groups) if idx in group)\n",
    "        pre_key_hex = bytes(pre_public_keys[group_idx]).hex()\n",
    "\n",
    "        feature = tree.tree_.feature.tolist()\n",
    "        value = tree.tree_.value.tolist()\n",
    "\n",
    "        jobs.append((idx, feature, value, group_idx, pre_key_hex))\n",
    "\n",
    "    # Encrypt labels in parallel using multithreading\n",
    "    results = Parallel(n_jobs=-1, backend=\"threading\")(\n",
    "        delayed(encrypt_single_tree)(idx, feature, value, group_idx, pre_key_hex, max_labels_per_tree)\n",
    "        for idx, feature, value, group_idx, pre_key_hex in jobs\n",
    "    )\n",
    "\n",
    "    encrypted_leaf_values, leaf_capsules = zip(*results)\n",
    "\n",
    "    end_label_encryption_time = time.perf_counter()\n",
    "    label_encryption_time = end_label_encryption_time - start_label_encryption_time\n",
    "\n",
    "    print(f\"PRE Label Encryption completed for {len(clf.estimators_)} trees.\")\n",
    "    print(f\"Total PRE Encryption Time (Parallel): {label_encryption_time:.4f} seconds\")\n",
    "\n",
    "    return list(encrypted_leaf_values), list(leaf_capsules), label_encryption_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96176ed5",
   "metadata": {},
   "source": [
    "### PRE Label Encryption with ThreadPoolExecutor\n",
    "\n",
    "This block performs parallel label encryption for each decision tree using `ThreadPoolExecutor`. The encrypted labels are computed using the `encrypt_single_tree` function, which uses a group's PRE public key. This approach is a multithreaded alternative to joblib and is especially useful when working with shared memory operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "db71623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d1154ec7b54526ae55c314f8596e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encrypting Trees with PRE:   0%|          | 0/1 [00:00<?, ?tree/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE Label Encryption completed for 1 trees.\n",
      "Total PRE Encryption Time (Threaded): 8.5723 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prepare encryption jobs: one per tree with associated group and PRE key\n",
    "jobs = []\n",
    "for idx, tree in enumerate(clf_ope.estimators_):\n",
    "    group_idx = next(i for i, group in enumerate(tree_groups) if idx in group)\n",
    "    pre_key_hex = bytes(pre_public_keys[group_idx]).hex()\n",
    "\n",
    "    feature = tree.tree_.feature.tolist()\n",
    "    value = tree.tree_.value.tolist()\n",
    "\n",
    "    jobs.append((idx, feature, value, group_idx, pre_key_hex))\n",
    "\n",
    "# Start timing the encryption process\n",
    "start_label_encryption_time = time.perf_counter()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Run encryption tasks using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(encrypt_single_tree, idx, feature, value, group_idx, pre_key_hex)\n",
    "        for idx, feature, value, group_idx, pre_key_hex in jobs\n",
    "    ]\n",
    "\n",
    "    # Collect results as they complete\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Encrypting Trees with PRE\", unit=\"tree\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "end_label_encryption_time = time.perf_counter()\n",
    "label_encryption_time = end_label_encryption_time - start_label_encryption_time\n",
    "\n",
    "# Report encryption summary\n",
    "print(f\"PRE Label Encryption completed for {len(results)} trees.\")\n",
    "print(f\"Total PRE Encryption Time (Threaded): {label_encryption_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8659a6",
   "metadata": {},
   "source": [
    "### Threshold Encryption with OPE (Parallel)\n",
    "\n",
    "This section encrypts the split thresholds of each decision tree using Order-Preserving Encryption (OPE). It:\n",
    "\n",
    "- Checks if encrypted thresholds are already cached for each tree.\n",
    "- If not cached, encrypts and stores them.\n",
    "- Executes the process in parallel across all decision trees using `joblib`.\n",
    "\n",
    "The encrypted thresholds are saved per-tree to avoid redundant encryption on future runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0f36d0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encrypted Thresholds for 1 trees\n",
      "Threshold Encryption Time (Parallel): 0.9041 seconds\n"
     ]
    }
   ],
   "source": [
    "# Make sure the output directory exists\n",
    "os.makedirs(\"Encrypted_Thresholds\", exist_ok=True)\n",
    "\n",
    "start_threshold_encryption_time = time.perf_counter()\n",
    "\n",
    "# Encrypt thresholds for a single tree and save to file\n",
    "def encrypt_thresholds_for_tree(idx, threshold_list, ope, key_name):\n",
    "    file_path = f\"Encrypted_Thresholds/encrypted_thresholds_{key_name}.npy\"\n",
    "\n",
    "    # If cached file exists, load it\n",
    "    if os.path.exists(file_path):\n",
    "        thresholds = np.load(file_path, allow_pickle=True).tolist()\n",
    "        print(f\"Loaded cached thresholds for key {key_name[:8]}...\")\n",
    "        return thresholds\n",
    "    else:\n",
    "        print(f\"Encrypting thresholds for key {key_name[:8]}...\")\n",
    "\n",
    "        # Encrypt each threshold (skip value -2, which marks a leaf)\n",
    "        tree_thresholds = [\n",
    "            ope.encrypt(int(th)) if th != -2 else None\n",
    "            for th in threshold_list\n",
    "        ]\n",
    "\n",
    "        # Save encrypted thresholds\n",
    "        np.save(file_path, tree_thresholds)\n",
    "        print(f\"Saved thresholds to {file_path}\")\n",
    "        return tree_thresholds\n",
    "\n",
    "# Prepare data for parallel execution: (tree index, thresholds, OPE key, key name)\n",
    "tree_threshold_data = [\n",
    "    (idx, tree.tree_.threshold.tolist(), ope_keys[idx], key_data[\"ope_keys\"][idx])\n",
    "    for idx, tree in enumerate(clf_ope.estimators_)\n",
    "]\n",
    "\n",
    "# Encrypt all thresholds in parallel\n",
    "encrypted_thresholds = Parallel(n_jobs=-1)(\n",
    "    delayed(encrypt_thresholds_for_tree)(idx, threshold_list, ope, key_name)\n",
    "    for idx, threshold_list, ope, key_name in tree_threshold_data\n",
    ")\n",
    "\n",
    "end_threshold_encryption_time = time.perf_counter()\n",
    "threshold_encryption_time = end_threshold_encryption_time - start_threshold_encryption_time\n",
    "\n",
    "print(f\"\\nEncrypted Thresholds for {len(encrypted_thresholds)} trees\")\n",
    "print(f\"Threshold Encryption Time (Parallel): {threshold_encryption_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2607c",
   "metadata": {},
   "source": [
    "### Dataset Encryption with OPE Per Tree\n",
    "\n",
    "This block encrypts the input dataset using Order-Preserving Encryption (OPE), generating one encrypted version of the dataset for each OPE key (typically one per decision tree).\n",
    "\n",
    "- `encrypt_image`: Encrypts a single image (row of pixel values).\n",
    "- `encrypt_dataset_with_ope`: Iterates over all OPE keys and applies encryption to the entire dataset, storing each result for later use in tree-specific classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "672ae89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encrypt a single image using an OPE key\n",
    "def encrypt_image(image, ope_key):\n",
    "    return [ope_key.encrypt(int(pixel)) for pixel in image]\n",
    "\n",
    "# Encrypt the entire dataset once for each OPE key (e.g., one per decision tree)\n",
    "def encrypt_dataset_with_ope(X, ope_keys):\n",
    "    encrypted_versions = []\n",
    "\n",
    "    for idx, ope_key in enumerate(ope_keys):\n",
    "        print(f\"\\nEncrypting dataset for Tree {idx + 1} using OPE Key {idx + 1}\")\n",
    "        start_tree_time = time.time()\n",
    "\n",
    "        # Encrypt each image in the dataset using the current OPE key\n",
    "        encrypted_X = [\n",
    "            encrypt_image(image, ope_key)\n",
    "            for image in tqdm(X, desc=f\"Encrypting for Tree {idx + 1}\")\n",
    "        ]\n",
    "\n",
    "        total_time = time.time() - start_tree_time\n",
    "        print(f\"Done: {len(encrypted_X)} images encrypted for Tree {idx + 1} in {total_time:.2f} sec\")\n",
    "\n",
    "        encrypted_versions.append(np.array(encrypted_X))\n",
    "\n",
    "    return encrypted_versions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8347f5",
   "metadata": {},
   "source": [
    "### Grouped Majority Voting with PRE\n",
    "\n",
    "This function performs majority voting across encrypted prediction groups, with added error handling:\n",
    "\n",
    "- It identifies the majority vote in each group.\n",
    "- Re-encrypts and decrypts the vote using PRE.\n",
    "- Catches and logs any errors during re-encryption, decryption, or decoding.\n",
    "\n",
    "If decryption or decoding fails, a fallback label of `'0'` is used to ensure continuity in the final vote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b03d69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grouped majority voting using PRE with error handling for decoding and decryption\n",
    "def grouped_majority_voting_with_pre(grouped_votes, grouped_capsules, group_keys, group_kfrags, vote_secret_key):\n",
    "    final_votes = []\n",
    "\n",
    "    for i in range(len(grouped_votes)):\n",
    "        try:\n",
    "            # Get the majority vote within the current group\n",
    "            group_vote = Counter(grouped_votes[i]).most_common(1)[0][0]\n",
    "            capsule = grouped_capsules[i][0]\n",
    "            kfrag = group_kfrags[i][0]\n",
    "\n",
    "            # Re-encrypt the capsule and verify\n",
    "            cfrag = reencrypt(capsule, kfrag)\n",
    "            verified_cfrag = VerifiedCapsuleFrag(cfrag)\n",
    "\n",
    "            # Decrypt the re-encrypted ciphertext\n",
    "            decrypted, _ = decrypt_pre(\n",
    "                ciphertext=group_vote,\n",
    "                capsule=capsule,\n",
    "                kfrags=[verified_cfrag],\n",
    "                vote_secret_key=vote_secret_key,\n",
    "                delegating_pk=group_keys[i]\n",
    "            )\n",
    "\n",
    "            # Try decoding the decrypted label; fallback to \"0\" if decoding fails\n",
    "            try:\n",
    "                label = decrypted.decode()\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Decode failed for group {i}, using fallback label '0'. Error: {e}\")\n",
    "                label = \"0\"\n",
    "\n",
    "            final_votes.append(label)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch any error during voting for this group and fallback\n",
    "            print(f\"[ERROR] Failed voting for group {i}: {e}\")\n",
    "            final_votes.append(\"0\")\n",
    "\n",
    "    # Perform overall majority voting from all group results\n",
    "    return Counter(final_votes).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58264ca3",
   "metadata": {},
   "source": [
    "### Secure Classification with Encrypted Random Forest\n",
    "\n",
    "This function performs secure classification using a multi-key encrypted Random Forest model. It:\n",
    "\n",
    "- Traverses each tree to find the leaf node for the input sample.\n",
    "- Retrieves the encrypted label and associated capsule.\n",
    "- Groups votes by encryption key for grouped decryption.\n",
    "- Performs secure grouped voting using Proxy Re-Encryption (PRE).\n",
    "- Measures and returns traversal time, label access time, voting time, and decryption time (if tracked).\n",
    "\n",
    "This function is designed for performance evaluation under full encryption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f03f7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform secure classification using PRE-encrypted labels and grouped voting\n",
    "def secure_classify(model, encrypted_X_per_tree, encrypted_thresholds, encrypted_leaf_values,\n",
    "                    leaf_capsules, tree_public_keys, kfrags_list, vote_secret_key, tree_groups):\n",
    "    \n",
    "    traversal_time = 0\n",
    "    label_access_time = 0\n",
    "    voting_time = 0\n",
    "\n",
    "    encrypted_votes = []\n",
    "    capsules = []\n",
    "\n",
    "    # Traverse all trees and collect encrypted labels and capsules\n",
    "    for tree_idx, tree in enumerate(model.estimators_):\n",
    "        start_traversal = time.perf_counter()\n",
    "        node = 0\n",
    "        tree_thresholds = encrypted_thresholds[tree_idx]\n",
    "        encrypted_X = encrypted_X_per_tree[tree_idx]\n",
    "\n",
    "        # Traverse the tree using encrypted thresholds\n",
    "        while tree.tree_.feature[node] != -2:\n",
    "            feature_idx = tree.tree_.feature[node]\n",
    "            encrypted_threshold = tree_thresholds[node]\n",
    "\n",
    "            if encrypted_X[feature_idx] < encrypted_threshold:\n",
    "                node = tree.tree_.children_left[node]\n",
    "            else:\n",
    "                node = tree.tree_.children_right[node]\n",
    "\n",
    "        traversal_time += time.perf_counter() - start_traversal\n",
    "\n",
    "        # Retrieve the encrypted label and capsule for the reached leaf node\n",
    "        start_label = time.perf_counter()\n",
    "        encrypted_label = encrypted_leaf_values[tree_idx][node]\n",
    "        capsule = leaf_capsules[tree_idx][node]\n",
    "        label_access_time += time.perf_counter() - start_label\n",
    "\n",
    "        encrypted_votes.append(encrypted_label)\n",
    "        capsules.append(capsule)\n",
    "\n",
    "    # Group votes and capsules by encryption group (based on PRE keys)\n",
    "    grouped_votes = []\n",
    "    grouped_capsules = []\n",
    "    group_keys = []\n",
    "    group_kfrags = []\n",
    "\n",
    "    for group_idx, group in enumerate(tree_groups):\n",
    "        group_votes = [encrypted_votes[i] for i in group]\n",
    "        group_caps = [capsules[i] for i in group]\n",
    "\n",
    "        grouped_votes.append(group_votes)\n",
    "        grouped_capsules.append(group_caps)\n",
    "        group_keys.append(tree_public_keys[group_idx])\n",
    "        group_kfrags.append(kfrags_list[group_idx])\n",
    "\n",
    "    # Perform grouped majority voting and measure its time\n",
    "    start_voting = time.perf_counter()\n",
    "    result = grouped_majority_voting_with_pre(\n",
    "        grouped_votes,\n",
    "        grouped_capsules,\n",
    "        group_keys,\n",
    "        group_kfrags,\n",
    "        vote_secret_key\n",
    "    )\n",
    "    voting_time += time.perf_counter() - start_voting\n",
    "\n",
    "\n",
    "    return result, traversal_time, label_access_time, voting_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52b50c",
   "metadata": {},
   "source": [
    "### Secure Classification for a Single Encrypted Sample\n",
    "\n",
    "This function performs secure classification on a single encrypted input sample using the multi-key Random Forest model.\n",
    "\n",
    "Steps involved:\n",
    "- Retrieves the encrypted sample for each tree.\n",
    "- Passes the sample through the `secure_classify` function for tree traversal, label decryption, and grouped voting.\n",
    "- Measures the total time taken and returns timing details for:\n",
    "  - Tree traversal\n",
    "  - Label access\n",
    "  - Grouped voting\n",
    "  - Total execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "64785e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secure classification for a single encrypted sample\n",
    "def secure_classify_sample(sample_idx, model, X_encrypted_per_tree, encrypted_thresholds,\n",
    "                           encrypted_leaf_values, leaf_capsules,\n",
    "                           tree_public_keys, kfrags_list, vote_secret_key, tree_groups):\n",
    "    # Get the encrypted sample for each tree\n",
    "    sample_per_tree = [X_encrypted_per_tree[tree_idx][sample_idx] for tree_idx in range(len(model.estimators_))]\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # Perform secure classification\n",
    "    pred, t_traversal, t_label, t_vote = secure_classify(\n",
    "        model=model,\n",
    "        encrypted_X_per_tree=sample_per_tree,\n",
    "        encrypted_thresholds=encrypted_thresholds,\n",
    "        encrypted_leaf_values=encrypted_leaf_values,\n",
    "        leaf_capsules=leaf_capsules,\n",
    "        tree_public_keys=tree_public_keys,\n",
    "        kfrags_list=kfrags_list,\n",
    "        vote_secret_key=vote_secret_key,\n",
    "        tree_groups=tree_groups\n",
    "    )\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    total_time = end - start\n",
    "\n",
    "    return pred, t_traversal, t_label, t_vote, total_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb929125",
   "metadata": {},
   "source": [
    "### Secure Classification for Full Dataset (Parallel)\n",
    "\n",
    "This function performs secure classification for an entire encrypted dataset using a multi-key Random Forest model with Proxy Re-Encryption.\n",
    "\n",
    "- It classifies each sample in parallel using `secure_classify_sample`.\n",
    "- Aggregates timing metrics for:\n",
    "  - Tree traversal\n",
    "  - Label access\n",
    "  - Grouped voting\n",
    "  - Total time\n",
    "- Returns both the predicted labels and a dictionary of performance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7e6390a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Securely classify an entire encrypted dataset in parallel\n",
    "def secure_classify_dataset(model, X_encrypted_per_tree, encrypted_thresholds, encrypted_leaf_values,\n",
    "                             leaf_capsules, tree_public_keys, kfrags_list, vote_secret_key, tree_groups):\n",
    "    num_samples = len(X_encrypted_per_tree[0])\n",
    "    print(\"Starting parallel classification...\")\n",
    "\n",
    "    # Classify each sample in parallel\n",
    "    results = Parallel(n_jobs=-1, prefer=\"threads\")(\n",
    "        delayed(secure_classify_sample)(\n",
    "            sample_idx, model, X_encrypted_per_tree, encrypted_thresholds,\n",
    "            encrypted_leaf_values, leaf_capsules,\n",
    "            tree_public_keys, kfrags_list, vote_secret_key, tree_groups\n",
    "        ) for sample_idx in tqdm(range(num_samples))\n",
    "    )\n",
    "\n",
    "    # Initialize accumulators for timing and predictions\n",
    "    predictions = []\n",
    "    total_traversal = total_label_access = total_voting = total_time = 0\n",
    "\n",
    "    # Aggregate results from all samples\n",
    "    for pred, t_traversal, t_label, t_vote, t_total in results:\n",
    "        predictions.append(pred)\n",
    "        total_traversal += t_traversal\n",
    "        total_label_access += t_label\n",
    "        total_voting += t_vote\n",
    "        total_time += t_total\n",
    "\n",
    "    overall_time = total_time\n",
    "\n",
    "    # Return predictions and detailed timing information\n",
    "    timings = {\n",
    "        \"samples\": num_samples,\n",
    "        \"classification_time\": total_time,\n",
    "        \"overall_time\": total_time,\n",
    "        \"avg_per_sample\": total_time / num_samples,\n",
    "        \"traversal_time\": total_traversal,\n",
    "        \"label_access_time\": total_label_access,\n",
    "        \"voting_time\": total_voting\n",
    "    }\n",
    "\n",
    "    return np.array(predictions), timings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfdd3f",
   "metadata": {},
   "source": [
    "### Grouped kfrag Generation and Secure Classification Execution\n",
    "\n",
    "This section performs the final secure classification using Proxy Re-Encryption (PRE):\n",
    "\n",
    "- Generates one `kfrag` set per encryption group (not per tree).\n",
    "- Builds a simplified list of PRE public keys for each group.\n",
    "- Runs secure classification across the encrypted test set using `secure_classify_dataset`.\n",
    "- Prints predictions, true labels, and a detailed breakdown of timing metrics, including:\n",
    "  - Total classification time\n",
    "  - Tree traversal time\n",
    "  - Label access time\n",
    "  - Voting time\n",
    "  - Average time per sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0c6e4ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Secure Classification with PRE (Grouped)...\n",
      "Starting parallel classification...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb5906117b34547a4ab144e15953665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['8' '4' '3' ... '2' '7' '1']\n",
      "True Labels: [8 4 8 ... 2 7 1]\n",
      "Secure Classification Time: 55.9697 seconds\n",
      "\n",
      "===== Classification Timing Summary =====\n",
      "samples: 14000\n",
      "Classification time: 893.5567 seconds\n",
      "Overall time: 893.5567 seconds\n",
      "Avg per sample: 0.0638 seconds\n",
      "Traversal time: 1.1407 seconds\n",
      "Label access time: 0.0425 seconds\n",
      "Voting time: 892.1942 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generate kfrags for each group (not per tree)\n",
    "signers = [Signer(sk) for sk in pre_secret_keys]\n",
    "\n",
    "kfrags_list = [\n",
    "    generate_kfrags(\n",
    "        delegating_sk=pre_secret_keys[group_idx],\n",
    "        receiving_pk=vote_public_key,\n",
    "        signer=signers[group_idx],\n",
    "        threshold=1,\n",
    "        shares=1,\n",
    "        sign_delegating_key=True,\n",
    "        sign_receiving_key=True\n",
    "    )\n",
    "    for group_idx in range(len(tree_groups))\n",
    "]\n",
    "\n",
    "# Optionally prepare the list of PRE public keys used per group\n",
    "tree_public_keys_points = [pre_public_keys[group_idx] for group_idx in range(len(tree_groups))]\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Performing Secure Classification with PRE (Grouped)...\")\n",
    "\n",
    "# Run secure classification for the entire encrypted test dataset\n",
    "y_pred_encrypted, timing_report = secure_classify_dataset(\n",
    "    model=clf_ope,\n",
    "    X_encrypted_per_tree=X_test_encrypted_per_tree,\n",
    "    encrypted_thresholds=encrypted_thresholds,\n",
    "    encrypted_leaf_values=encrypted_leaf_values,\n",
    "    leaf_capsules=leaf_capsules,\n",
    "    tree_public_keys=tree_public_keys_points,\n",
    "    kfrags_list=kfrags_list,\n",
    "    vote_secret_key=vote_secret_key,\n",
    "    tree_groups=tree_groups\n",
    ")\n",
    "\n",
    "# Display predictions and true labels\n",
    "print(\"Predictions:\", y_pred_encrypted)\n",
    "print(\"True Labels:\", y_test[:num_samples_testing])\n",
    "\n",
    "# Display total classification time\n",
    "classification_time = time.time() - start_time\n",
    "print(f\"Secure Classification Time: {classification_time:.4f} seconds\")\n",
    "\n",
    "# Display detailed classification timing report\n",
    "print(\"\\n===== Classification Timing Summary =====\")\n",
    "for key, value in timing_report.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key.replace('_', ' ').capitalize()}: {value:.4f} seconds\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f512b5",
   "metadata": {},
   "source": [
    "### Final Accuracy Evaluation\n",
    "\n",
    "This block verifies that the number of predictions matches the number of ground truth labels. If they match, it converts the predictions to integers and calculates the final accuracy score on the encrypted dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29fb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of predictions: 14000\n",
      "Length of ground truth: 14000\n",
      "Secure Random Forest Accuracy on Encrypted Dataset: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: ensure predictions match ground truth size\n",
    "print(\"Length of predictions:\", len(y_pred_encrypted))\n",
    "print(\"Length of ground truth:\", len(y_test))\n",
    "\n",
    "# Use only the number of samples classified (in case test set was sliced earlier)\n",
    "y_true = y_test[:len(y_pred_encrypted)]\n",
    "\n",
    "if len(y_pred_encrypted) == len(y_true):\n",
    "    # Convert predictions to integers\n",
    "    y_pred_encrypted = [int(p) for p in y_pred_encrypted]\n",
    "\n",
    "    # Calculate and print accuracy\n",
    "    secure_accuracy = accuracy_score(y_true, y_pred_encrypted)\n",
    "    print(f\"Secure Random Forest Accuracy on Encrypted Dataset: {secure_accuracy:.2f}\")\n",
    "else:\n",
    "    print(\"Error: Prediction length does not match test labels. Cannot compute accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ee566eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Optimized Multi-Key Framework (Chunked OPE + Threaded PRE) =====\n",
      "Available CPU Cores: 16\n",
      "\n",
      "===== Execution Time Summary =====\n",
      "Total Execution Time: 70.6341 seconds\n",
      "Dataset Load Time: 4.6908 seconds (6.64%)\n",
      "Test Data Encryption Time: 0.0413 seconds (0.06%)\n",
      "Label Encryption Time (PRE): 8.5723 seconds (12.14%)\n",
      "Random Forest Training Time: 0.4559 seconds (0.65%)\n",
      "Threshold Encryption Time: 0.9041 seconds (1.28%)\n",
      "Secure Classification Time: 55.9697 seconds (79.24%)\n",
      "\n",
      "----- Secure Classification Breakdown -----\n",
      "Tree Traversal Time: 1.1407 seconds\n",
      "Label Access Time: 0.0425 seconds\n",
      "Voting Time: 892.1942 seconds\n",
      "Average Time per Sample: 0.0638 seconds\n",
      "\n",
      "===== Secure Classification Results =====\n",
      "Secure Random Forest Accuracy on Encrypted MNIST: 0.8161\n",
      "Number of Decision Trees: 1\n",
      "Training Set Size: 56000 samples\n",
      "Testing Set Size: 14000 samples\n",
      "\n",
      "===== Throughput (Inference Only) =====\n",
      "Total Throughput Time (Test Data Encryption + Classification): 56.0111 seconds\n",
      "Throughput: 249.95 samples/second\n",
      "Encryption % of Throughput Time: 0.07%\n",
      "Classification % of Throughput Time: 99.93%\n",
      "\n",
      "===== Full Secure Pipeline Throughput =====\n",
      "Total Time (Test Data + Label + Threshold + Classification): 65.4875 seconds\n",
      "Throughput (Secure Pipeline): 213.78 samples/second\n",
      "\n",
      "===== Key Management Summary =====\n",
      "Number of OPE Keys Used: 1\n",
      "Number of PRE Public Keys Used: 1\n",
      "Key Assignment: 1 OPE/PRE key groups used across 1 trees\n",
      "\n",
      "Tree Group Structure:\n",
      "  Group 1: 1 trees\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Recompute actual total from all components to ensure percentages are meaningful\n",
    "effective_total_time = (\n",
    "    dataset_load_time +\n",
    "    test_data_encryption_time +\n",
    "    label_encryption_time +\n",
    "    training_time +\n",
    "    threshold_encryption_time +\n",
    "    classification_time\n",
    ")\n",
    "\n",
    "# Compute percentages\n",
    "dataset_load_percentage = (dataset_load_time / effective_total_time) * 100\n",
    "test_data_encryption_percentage = (test_data_encryption_time / effective_total_time) * 100\n",
    "label_encryption_percentage = (label_encryption_time / effective_total_time) * 100\n",
    "rf_training_percentage = (training_time / effective_total_time) * 100\n",
    "threshold_encryption_percentage = (threshold_encryption_time / effective_total_time) * 100\n",
    "classification_percentage = (classification_time / effective_total_time) * 100\n",
    "\n",
    "# Combine encryption and classification times\n",
    "total_throughput_time = test_data_encryption_time + classification_time\n",
    "encryption_percentage_throughput = (test_data_encryption_time / total_throughput_time) * 100\n",
    "classification_percentage_throughput = (classification_time / total_throughput_time) * 100\n",
    "\n",
    "# Full secure pipeline time\n",
    "total_secure_pipeline_time = (\n",
    "    test_data_encryption_time +\n",
    "    label_encryption_time +\n",
    "    threshold_encryption_time +\n",
    "    classification_time\n",
    ")\n",
    "throughput_secure_pipeline = len(X_test) / total_secure_pipeline_time\n",
    "\n",
    "# Start output\n",
    "print(\"\\n===== Optimized Multi-Key Framework (Chunked OPE + Threaded PRE) =====\")\n",
    "print(f\"Available CPU Cores: {multiprocessing.cpu_count()}\")\n",
    "\n",
    "# Timing summary\n",
    "print(\"\\n===== Execution Time Summary =====\")\n",
    "print(f\"Total Execution Time: {effective_total_time:.4f} seconds\")\n",
    "print(f\"Dataset Load Time: {dataset_load_time:.4f} seconds ({dataset_load_percentage:.2f}%)\")\n",
    "print(f\"Test Data Encryption Time: {test_data_encryption_time:.4f} seconds ({test_data_encryption_percentage:.2f}%)\")\n",
    "print(f\"Label Encryption Time (PRE): {label_encryption_time:.4f} seconds ({label_encryption_percentage:.2f}%)\")\n",
    "print(f\"Random Forest Training Time: {training_time:.4f} seconds ({rf_training_percentage:.2f}%)\")\n",
    "print(f\"Threshold Encryption Time: {threshold_encryption_time:.4f} seconds ({threshold_encryption_percentage:.2f}%)\")\n",
    "print(f\"Secure Classification Time: {classification_time:.4f} seconds ({classification_percentage:.2f}%)\")\n",
    "\n",
    "# Classification internals (if recorded)\n",
    "if \"timing_report\" in locals():\n",
    "    print(\"\\n----- Secure Classification Breakdown -----\")\n",
    "    print(f\"Tree Traversal Time: {timing_report['traversal_time']:.4f} seconds\")\n",
    "    print(f\"Label Access Time: {timing_report['label_access_time']:.4f} seconds\")\n",
    "    print(f\"Voting Time: {timing_report['voting_time']:.4f} seconds\")\n",
    "    print(f\"Average Time per Sample: {timing_report['avg_per_sample']:.4f} seconds\")\n",
    "\n",
    "# Accuracy & test/train data\n",
    "print(\"\\n===== Secure Classification Results =====\")\n",
    "print(f\"Secure Random Forest Accuracy on Encrypted MNIST: {secure_accuracy:.4f}\")\n",
    "print(f\"Number of Decision Trees: {num_estimators}\")\n",
    "print(f\"Training Set Size: {len(X_train)} samples\")\n",
    "print(f\"Testing Set Size: {len(X_test)} samples\")\n",
    "\n",
    "# Throughput (Inference Only)\n",
    "print(\"\\n===== Throughput (Inference Only) =====\")\n",
    "print(f\"Total Throughput Time (Test Data Encryption + Classification): {total_throughput_time:.4f} seconds\")\n",
    "print(f\"Throughput: {len(X_test) / total_throughput_time:.2f} samples/second\")\n",
    "print(f\"Encryption % of Throughput Time: {encryption_percentage_throughput:.2f}%\")\n",
    "print(f\"Classification % of Throughput Time: {classification_percentage_throughput:.2f}%\")\n",
    "\n",
    "# Full Secure Pipeline Throughput\n",
    "print(\"\\n===== Full Secure Pipeline Throughput =====\")\n",
    "print(f\"Total Time (Test Data + Label + Threshold + Classification): {total_secure_pipeline_time:.4f} seconds\")\n",
    "print(f\"Throughput (Secure Pipeline): {throughput_secure_pipeline:.2f} samples/second\")\n",
    "\n",
    "# Key assignment summary\n",
    "print(\"\\n===== Key Management Summary =====\")\n",
    "print(f\"Number of OPE Keys Used: {len(ope_keys)}\")\n",
    "print(f\"Number of PRE Public Keys Used: {len(pre_public_keys)}\")\n",
    "print(f\"Key Assignment: {len(tree_groups)} OPE/PRE key groups used across {num_estimators} trees\")\n",
    "\n",
    "print(\"\\nTree Group Structure:\")\n",
    "for i, group in enumerate(tree_groups):\n",
    "    print(f\"  Group {i + 1}: {len(group)} trees\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
